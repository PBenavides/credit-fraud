{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Model Delivering </center>\n",
    "\n",
    "This notebook it's about optimizing, training and deliver the final models. We will get some artifacts to preprocess features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SHAPE: (256326, 33)\n",
      "TEST SHAPE:(28481, 33)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "#SELECTED MODELS\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#LOAD DATA.\n",
    "data_path=(\n",
    "    '../input/',\n",
    "    )\n",
    "\n",
    "#ARTIFACTS PATH\n",
    "artifacts_path = (\n",
    "    '../artifacts/models/',\n",
    "    '../artifacts/'\n",
    "    )\n",
    "\n",
    "train = pd.read_csv(data_path[0]+'train.csv')\n",
    "test = pd.read_csv(data_path[0]+'test.csv')\n",
    "\n",
    "print('TRAIN SHAPE: {}\\nTEST SHAPE:{}'.format(train.shape, test.shape))\n",
    "\n",
    "#DEFINE Features and target\n",
    "train.drop('Time',axis=1, inplace=True)\n",
    "\n",
    "features = train.drop('Class', axis=1).columns.to_list()\n",
    "target = 'Class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reducing data Memory:**\n",
    "\n",
    "*Source: https://gist.github.com/fujiyuu75/748bc168c9ca8a49f86e144a08849893*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 62.58 MB\n",
      "Memory usage after optimization is: 15.40 MB\n",
      "Decreased by 75.4%\n",
      "Memory usage of dataframe is 7.17 MB\n",
      "Memory usage after optimization is: 1.82 MB\n",
      "Decreased by 74.6%\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        #else:\n",
    "        #    df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The preprocessing steps will be:\n",
    "\n",
    "- Normalize data: artifact needed is mean and std for each data column.\n",
    "\n",
    "- Create extra features: based on the previous automate feat eng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "artifacts_path = (\n",
    "    '../artifacts/models/',\n",
    "    '../artifacts/'\n",
    "    )\n",
    "\n",
    "x_train = train[features]\n",
    "x_test = test[features]\n",
    "\n",
    "all_data = pd.concat([x_train, x_test],axis=0) #Train the Normalizer with all the data\n",
    "\n",
    "normalizer = Normalizer().fit(all_data) # Fit inot the model\n",
    "\n",
    "norm_train = normalizer.transform(x_train.values)\n",
    "x_train = pd.DataFrame(norm_train, index=x_train.index, columns=x_train.columns)\n",
    "\n",
    "pickle.dump(normalizer, open(artifacts_path[1]+'normalizer.sav', 'wb')) #Save Normalizer as artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, recall_score, precision_score\n",
    "\n",
    "def auc_precision_recall_curve(y_true, y_preds):\n",
    "    \"\"\"Kaggle official doc from the data recommends this metric\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_preds)\n",
    "    #AUC function to calculate AUC of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall\n",
    "\n",
    "def compute_scores(y_true,y_preds):\n",
    "    \"\"\"Return a dictionary of results.\n",
    "    \n",
    "    It computes 4 metrics for Fraud Detection interests.\n",
    "    Arguments:\n",
    "    \n",
    "    y_true: real labeled data\n",
    "    y_preds: prediction from the model\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = {\n",
    "        'AUC-PRC': auc_precision_recall_curve(y_true, y_preds),\n",
    "        'F1-score': f1_score(y_true, y_preds),\n",
    "        'Recall': recall_score(y_true, y_preds),\n",
    "        'Precision': precision_score(y_true, y_preds)\n",
    "    }\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def score_report(score_dict, train=False):\n",
    "    \"\"\"Printed scores report\n",
    "    score_dict: dict from compute_scores function output.\n",
    "    \"\"\"\n",
    "    if train:\n",
    "        print('---'*10)\n",
    "        print('Train Scores:\\n')\n",
    "        for score_name, score_value in score_dict.items():\n",
    "            print(f\"{score_name}:  {score_value}\")\n",
    "    else:\n",
    "        print('Test Scores:\\n')\n",
    "        for score_name, score_value in score_dict.items():\n",
    "            print(f\"{score_name}:  {score_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(model, train_data, test_data, features, target, name, \n",
    "                artifacts_path='../artifacts/models/', tune=False, param_grid=None, final=True):\n",
    "    \"\"\" Train a Sklearn format model and make the final test\n",
    "    --------------\n",
    "    Parameters:\n",
    "    model: Model Instance.\n",
    "    train_dataset: training pd.DataFrame dataset\n",
    "    test_dataset: HoldOut pd.DataFrame dataset\n",
    "    features: List of features to be included.\n",
    "    target: target name\n",
    "    name: name to store the model\n",
    "    tune: If tuning job is calling.\n",
    "    returns a model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    #  for testing against test_data(not seeing until this point)\n",
    "    \n",
    "    x_train, y_train = train_data[features], train_data[target]\n",
    "    x_test, y_test = test_data[features], test_data[target]\n",
    "    \n",
    "    if tune == True:\n",
    "        \n",
    "        scorer = make_scorer(auc_precision_recall_curve, \n",
    "                             greater_is_better=True) #To optimize over AUC-RC\n",
    "        \n",
    "        model, results = tuning_job(\n",
    "                            model=model,\n",
    "                            data=train_data,\n",
    "                            features=features,\n",
    "                            target=target,\n",
    "                            param_grid=param_grid,\n",
    "                            cv=cv,\n",
    "                            scoring=scorer\n",
    "        )\n",
    "        \n",
    "    elif tune == False:\n",
    "        model.fit(x_train, y_train)\n",
    "    \n",
    "    if isinstance(model, XGBClassifier):\n",
    "        y_test_pred = model.predict(np.float32(x_test))\n",
    "    else:\n",
    "        y_test_pred = model.predict(x_test)\n",
    "    \n",
    "    #SCORES\n",
    "    test_results = compute_scores(y_test, y_test_pred)\n",
    "    score_report(test_results)\n",
    "    \n",
    "    #STORE\n",
    "    filename = artifacts_path + name +'.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    # INFERENCE TIME\n",
    "    random_sample = x_test.sample(n=1)\n",
    "    \n",
    "    start = time.time()\n",
    "    one_inf = model.predict(np.float32(random_sample))\n",
    "    end = time.time()\n",
    "    \n",
    "    print('One inference time:', end - start)\n",
    "    \n",
    "    #Re-train with all data if final==True\n",
    "    if final==True: #if model is final\n",
    "        all_data = pd.concat([train_data, test_data], axis=1)\n",
    "        model.fit(all_data[features], all_data[target])\n",
    "        return model\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def tuning_job(model, data, features, target, param_grid,scorer, cv=5):\n",
    "    \"\"\"Tunes the model and outputs best fit.\n",
    "    ----------\n",
    "    Parameters:\n",
    "    model: Sklearn instance or Sklearn wrapper\n",
    "    data: x_train data.\n",
    "    param_grid: search space of hyperparameters\n",
    "    \"\"\"\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "                    estimator = model,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=cv,\n",
    "                    scoring=scorer\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(np.float32(data[features]), np.float32(data[target]))\n",
    "    \n",
    "    results = grid_search.cv_results_\n",
    "    \n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    \n",
    "    return best_estimator, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Delivering:\n",
    "\n",
    "1.- LDA\n",
    "\n",
    "LDA does not need to be tuned. \n",
    "\n",
    "*Source: https://datascience.stackexchange.com/questions/21942/linear-discriminant-analysis-which-parameters-can-be-tunned-in-cross-validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores:\n",
      "\n",
      "AUC-PRC:  0.7077814377743654\n",
      "F1-score:  0.7032967032967032\n",
      "Recall:  0.6530612244897959\n",
      "Precision:  0.7619047619047619\n",
      "One inference time: 0.000997781753540039\n"
     ]
    }
   ],
   "source": [
    "#FOR LDA. \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "features = train.drop('Class', axis=1).columns.to_list()\n",
    "target = 'Class'\n",
    "name='first_lda'\n",
    "\n",
    "lda_model = build_model(model, train, test, features, target, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores:\n",
      "\n",
      "AUC-PRC:  0.8179149508193432\n",
      "F1-score:  0.8045977011494253\n",
      "Recall:  0.7142857142857143\n",
      "Precision:  0.9210526315789473\n",
      "One inference time: 0.022939443588256836\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(n_jobs=-1)\n",
    "name = 'first_et'\n",
    "et = build_model(model, train, test, features, target, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrindSearch Results:\n",
      " {'mean_fit_time': array([26.84591489,  4.64906516,  3.36830096,  7.20164361,  3.9055057 ,\n",
      "        3.96377382, 11.15993519,  3.57548676,  3.15751328, 13.71353145,\n",
      "        3.14232178,  2.44076271]), 'std_fit_time': array([5.0747395 , 0.87329246, 0.73621437, 1.00676932, 1.47386738,\n",
      "       1.02449758, 0.23057305, 0.42737733, 0.40138549, 1.95225189,\n",
      "       1.10233683, 0.20201187]), 'mean_score_time': array([1.06514654, 0.30422077, 0.22383952, 0.27955313, 0.22403827,\n",
      "       0.23425202, 0.41798396, 0.27053308, 0.20831175, 0.4546319 ,\n",
      "       0.26361718, 0.18921418]), 'std_score_time': array([0.41180104, 0.07648922, 0.05909967, 0.08515743, 0.04513269,\n",
      "       0.03960724, 0.02948248, 0.03128417, 0.06054472, 0.1911039 ,\n",
      "       0.08305488, 0.02321461]), 'param_max_depth': masked_array(data=[None, None, None, 5, 5, 5, 10, 10, 10, 12, 12, 12],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_impurity_decrease': masked_array(data=[0, 0.2, 0.5, 0, 0.2, 0.5, 0, 0.2, 0.5, 0, 0.2, 0.5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': None, 'min_impurity_decrease': 0}, {'max_depth': None, 'min_impurity_decrease': 0.2}, {'max_depth': None, 'min_impurity_decrease': 0.5}, {'max_depth': 5, 'min_impurity_decrease': 0}, {'max_depth': 5, 'min_impurity_decrease': 0.2}, {'max_depth': 5, 'min_impurity_decrease': 0.5}, {'max_depth': 10, 'min_impurity_decrease': 0}, {'max_depth': 10, 'min_impurity_decrease': 0.2}, {'max_depth': 10, 'min_impurity_decrease': 0.5}, {'max_depth': 12, 'min_impurity_decrease': 0}, {'max_depth': 12, 'min_impurity_decrease': 0.2}, {'max_depth': 12, 'min_impurity_decrease': 0.5}], 'split0_test_score': array([0.84464287, 0.50086802, 0.50086802, 0.68925059, 0.50086802,\n",
      "       0.50086802, 0.77397718, 0.50086802, 0.50086802, 0.82123246,\n",
      "       0.50086802, 0.50086802]), 'split1_test_score': array([0.89495007, 0.50085829, 0.50085829, 0.68549167, 0.50085829,\n",
      "       0.50085829, 0.81608502, 0.50085829, 0.50085829, 0.85271762,\n",
      "       0.50085829, 0.50085829]), 'split2_test_score': array([0.8735337 , 0.50085829, 0.50085829, 0.61847317, 0.50085829,\n",
      "       0.50085829, 0.77266703, 0.50085829, 0.50085829, 0.82834763,\n",
      "       0.50085829, 0.50085829]), 'split3_test_score': array([0.85397005, 0.50086804, 0.50086804, 0.60138385, 0.50086804,\n",
      "       0.50086804, 0.8044603 , 0.50086804, 0.50086804, 0.84168675,\n",
      "       0.50086804, 0.50086804]), 'split4_test_score': array([0.86794158, 0.50086804, 0.50086804, 0.64107365, 0.50086804,\n",
      "       0.50086804, 0.78127925, 0.50086804, 0.50086804, 0.84637367,\n",
      "       0.50086804, 0.50086804]), 'mean_test_score': array([0.86700765, 0.50086413, 0.50086413, 0.64713458, 0.50086413,\n",
      "       0.50086413, 0.78969376, 0.50086413, 0.50086413, 0.83807163,\n",
      "       0.50086413, 0.50086413]), 'std_test_score': array([1.72881590e-02, 4.77533272e-06, 4.77533272e-06, 3.52033110e-02,\n",
      "       4.77533272e-06, 4.77533272e-06, 1.74486296e-02, 4.77533272e-06,\n",
      "       4.77533272e-06, 1.16156094e-02, 4.77533272e-06, 4.77533272e-06]), 'rank_test_score': array([1, 5, 5, 4, 5, 5, 3, 5, 5, 2, 5, 5])}\n"
     ]
    }
   ],
   "source": [
    "#Tune model: test\n",
    "param_grid = {'max_depth':[None, 5,10,12], 'min_impurity_decrease':[0,0.2,0.5]}\n",
    "\n",
    "scorer = make_scorer(auc_precision_recall_curve, \n",
    "                             greater_is_better=True)\n",
    "\n",
    "best_et, results = tuning_job(model, train, features, target, param_grid,scorer, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores:\n",
      "\n",
      "AUC-PRC:  0.8291136226376261\n",
      "F1-score:  0.8181818181818182\n",
      "Recall:  0.7346938775510204\n",
      "Precision:  0.9230769230769231\n",
      "One inference time: 0.023936748504638672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(min_impurity_decrease=0, n_jobs=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='tuned_et'\n",
    "build_model(best_et, train, test, features, target, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Scores:\n",
      "\n",
      "AUC-PRC:  0.8289811993635815\n",
      "F1-score:  0.8222222222222222\n",
      "Recall:  0.7551020408163265\n",
      "Precision:  0.9024390243902439\n",
      "One inference time: 0.0059850215911865234\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "name = 'first_xgb'\n",
    "xgb_ = build_model(model, train, test, features, target, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:23:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:23:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:24:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:24:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.03)\n",
    "\n",
    "param_grid = {'eta':[0.1, 0.01, 0.4],\n",
    "              'max_depth':[5, 20, None]}\n",
    "\n",
    "xgb_tuned, results = tuning_job(model, train, features, target, param_grid,scorer, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.400000006,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 20,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 4,\n",
       " 'num_parallel_tree': 1,\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None,\n",
       " 'eta': 0.4}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tuned.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:36:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Scores:\n",
      "\n",
      "AUC-PRC:  0.8175751610991646\n",
      "F1-score:  0.8089887640449438\n",
      "Recall:  0.7346938775510204\n",
      "Precision:  0.9\n",
      "One inference time: 0.015623331069946289\n"
     ]
    }
   ],
   "source": [
    "name = 'tuned_xgb'\n",
    "tuned_xgb = build_model(xgb_tuned, train, test, features, target, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Stacked Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-44-4b498f0a1e2f>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-44-4b498f0a1e2f>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    estimators=estimators, final_estimator)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('et', best_et),\n",
    "    ('lda', lda_model),\n",
    "    ('xgb', tuned_xgb\n",
    "    )\n",
    "]\n",
    "\n",
    "clf = StackingClassifer(estimators=estimators, final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>sin_time</th>\n",
       "      <th>cos_time</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.080078</td>\n",
       "      <td>-0.005001</td>\n",
       "      <td>-2.033203</td>\n",
       "      <td>-0.024338</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>-1.508789</td>\n",
       "      <td>0.608398</td>\n",
       "      <td>-0.379883</td>\n",
       "      <td>0.139404</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018539</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.338135</td>\n",
       "      <td>0.225586</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>-0.092041</td>\n",
       "      <td>0.770020</td>\n",
       "      <td>-0.994629</td>\n",
       "      <td>-0.105774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.037109</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>-1.794922</td>\n",
       "      <td>0.245361</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>-0.350342</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>-0.016663</td>\n",
       "      <td>0.334473</td>\n",
       "      <td>-0.201294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311035</td>\n",
       "      <td>0.181396</td>\n",
       "      <td>-0.291504</td>\n",
       "      <td>0.175659</td>\n",
       "      <td>-0.067505</td>\n",
       "      <td>-0.044617</td>\n",
       "      <td>2.679688</td>\n",
       "      <td>-0.739258</td>\n",
       "      <td>-0.673340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.523926</td>\n",
       "      <td>-0.564453</td>\n",
       "      <td>1.616211</td>\n",
       "      <td>-1.689453</td>\n",
       "      <td>-0.859863</td>\n",
       "      <td>1.282227</td>\n",
       "      <td>-0.690918</td>\n",
       "      <td>0.151733</td>\n",
       "      <td>0.566895</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030853</td>\n",
       "      <td>0.221191</td>\n",
       "      <td>-1.251953</td>\n",
       "      <td>1.052734</td>\n",
       "      <td>-0.499023</td>\n",
       "      <td>-0.010262</td>\n",
       "      <td>45.812500</td>\n",
       "      <td>0.289307</td>\n",
       "      <td>-0.957031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.966797</td>\n",
       "      <td>-0.220825</td>\n",
       "      <td>-0.377930</td>\n",
       "      <td>0.177124</td>\n",
       "      <td>-0.306885</td>\n",
       "      <td>-0.077576</td>\n",
       "      <td>-0.530762</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391846</td>\n",
       "      <td>0.744629</td>\n",
       "      <td>-0.424072</td>\n",
       "      <td>-0.674316</td>\n",
       "      <td>0.032074</td>\n",
       "      <td>-0.031464</td>\n",
       "      <td>1.179688</td>\n",
       "      <td>-0.319580</td>\n",
       "      <td>-0.947754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.350586</td>\n",
       "      <td>-0.152100</td>\n",
       "      <td>-0.045654</td>\n",
       "      <td>-0.059753</td>\n",
       "      <td>-0.416748</td>\n",
       "      <td>-0.672363</td>\n",
       "      <td>-0.224487</td>\n",
       "      <td>-0.044922</td>\n",
       "      <td>0.641602</td>\n",
       "      <td>-0.049011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146240</td>\n",
       "      <td>-0.432373</td>\n",
       "      <td>0.436523</td>\n",
       "      <td>1.174805</td>\n",
       "      <td>-0.097656</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>3.119141</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>-0.993164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256321</th>\n",
       "      <td>-0.582520</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>1.481445</td>\n",
       "      <td>1.020508</td>\n",
       "      <td>0.868164</td>\n",
       "      <td>1.958008</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>-0.862305</td>\n",
       "      <td>-0.042053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260498</td>\n",
       "      <td>-1.380859</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.095459</td>\n",
       "      <td>0.153320</td>\n",
       "      <td>0.051178</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>-0.333008</td>\n",
       "      <td>-0.942871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256322</th>\n",
       "      <td>-1.354492</td>\n",
       "      <td>3.476562</td>\n",
       "      <td>-1.436523</td>\n",
       "      <td>4.214844</td>\n",
       "      <td>1.027344</td>\n",
       "      <td>0.183228</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>-0.039154</td>\n",
       "      <td>-0.199585</td>\n",
       "      <td>3.876953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149292</td>\n",
       "      <td>-0.827148</td>\n",
       "      <td>-0.340820</td>\n",
       "      <td>-0.000825</td>\n",
       "      <td>0.383545</td>\n",
       "      <td>-0.164429</td>\n",
       "      <td>2.689453</td>\n",
       "      <td>-0.815918</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256323</th>\n",
       "      <td>1.758789</td>\n",
       "      <td>-1.265625</td>\n",
       "      <td>-1.185547</td>\n",
       "      <td>-0.483398</td>\n",
       "      <td>-1.098633</td>\n",
       "      <td>-0.801758</td>\n",
       "      <td>-0.773438</td>\n",
       "      <td>-0.062561</td>\n",
       "      <td>-0.176270</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043243</td>\n",
       "      <td>-0.020050</td>\n",
       "      <td>-0.265381</td>\n",
       "      <td>-0.130371</td>\n",
       "      <td>-0.008781</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>-0.982422</td>\n",
       "      <td>-0.186646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256324</th>\n",
       "      <td>1.187500</td>\n",
       "      <td>-0.371094</td>\n",
       "      <td>0.911133</td>\n",
       "      <td>0.794434</td>\n",
       "      <td>-1.244141</td>\n",
       "      <td>-0.788574</td>\n",
       "      <td>-0.322754</td>\n",
       "      <td>-0.192139</td>\n",
       "      <td>-0.731445</td>\n",
       "      <td>0.598633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128662</td>\n",
       "      <td>0.879395</td>\n",
       "      <td>0.350586</td>\n",
       "      <td>-0.564453</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>49.968750</td>\n",
       "      <td>-0.516113</td>\n",
       "      <td>0.856445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256325</th>\n",
       "      <td>-0.343262</td>\n",
       "      <td>1.211914</td>\n",
       "      <td>1.319336</td>\n",
       "      <td>0.051117</td>\n",
       "      <td>0.146851</td>\n",
       "      <td>-0.960938</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>-0.138428</td>\n",
       "      <td>-0.571289</td>\n",
       "      <td>-0.543945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031342</td>\n",
       "      <td>0.361084</td>\n",
       "      <td>-0.120483</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>0.253418</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>1.790039</td>\n",
       "      <td>-0.696289</td>\n",
       "      <td>0.717773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256326 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0       2.080078 -0.005001 -2.033203 -0.024338  0.354004 -1.508789  0.608398   \n",
       "1       2.037109  0.048676 -1.794922  0.245361  0.567871 -0.350342  0.025803   \n",
       "2      -0.523926 -0.564453  1.616211 -1.689453 -0.859863  1.282227 -0.690918   \n",
       "3       1.966797 -0.220825 -0.377930  0.177124 -0.306885 -0.077576 -0.530762   \n",
       "4       1.350586 -0.152100 -0.045654 -0.059753 -0.416748 -0.672363 -0.224487   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "256321 -0.582520  0.749023  1.481445  1.020508  0.868164  1.958008  0.080078   \n",
       "256322 -1.354492  3.476562 -1.436523  4.214844  1.027344  0.183228  0.783691   \n",
       "256323  1.758789 -1.265625 -1.185547 -0.483398 -1.098633 -0.801758 -0.773438   \n",
       "256324  1.187500 -0.371094  0.911133  0.794434 -1.244141 -0.788574 -0.322754   \n",
       "256325 -0.343262  1.211914  1.319336  0.051117  0.146851 -0.960938  0.781250   \n",
       "\n",
       "              V8        V9       V10  ...       V23       V24       V25  \\\n",
       "0      -0.379883  0.139404  0.223022  ... -0.018539  0.040619  0.338135   \n",
       "1      -0.016663  0.334473 -0.201294  ...  0.311035  0.181396 -0.291504   \n",
       "2       0.151733  0.566895  0.703125  ...  0.030853  0.221191 -1.251953   \n",
       "3       0.073242  0.749023  0.008385  ...  0.391846  0.744629 -0.424072   \n",
       "4      -0.044922  0.641602 -0.049011  ... -0.146240 -0.432373  0.436523   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "256321  0.765625 -0.862305 -0.042053  ... -0.260498 -1.380859  0.008530   \n",
       "256322 -0.039154 -0.199585  3.876953  ...  0.149292 -0.827148 -0.340820   \n",
       "256323 -0.062561 -0.176270  0.181641  ... -0.043243 -0.020050 -0.265381   \n",
       "256324 -0.192139 -0.731445  0.598633  ...  0.128662  0.879395  0.350586   \n",
       "256325 -0.138428 -0.571289 -0.543945  ... -0.031342  0.361084 -0.120483   \n",
       "\n",
       "             V26       V27       V28      Amount  sin_time  cos_time  Class  \n",
       "0       0.225586 -0.094727 -0.092041    0.770020 -0.994629 -0.105774      0  \n",
       "1       0.175659 -0.067505 -0.044617    2.679688 -0.739258 -0.673340      0  \n",
       "2       1.052734 -0.499023 -0.010262   45.812500  0.289307 -0.957031      0  \n",
       "3      -0.674316  0.032074 -0.031464    1.179688 -0.319580 -0.947754      0  \n",
       "4       1.174805 -0.097656 -0.012512    3.119141  0.114746 -0.993164      0  \n",
       "...          ...       ...       ...         ...       ...       ...    ...  \n",
       "256321  0.095459  0.153320  0.051178    2.380859 -0.333008 -0.942871      0  \n",
       "256322 -0.000825  0.383545 -0.164429    2.689453 -0.815918 -0.578125      0  \n",
       "256323 -0.130371 -0.008781  0.008514  189.000000 -0.982422 -0.186646      0  \n",
       "256324 -0.564453  0.062500  0.046387   49.968750 -0.516113  0.856445      0  \n",
       "256325  0.068298  0.253418  0.100830    1.790039 -0.696289  0.717773      0  \n",
       "\n",
       "[256326 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STACKING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
